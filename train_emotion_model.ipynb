{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T22:58:37.094265Z",
     "start_time": "2025-06-15T22:58:29.303847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ],
   "id": "51d35e35ca2c6939",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-15T22:58:40.216499Z",
     "start_time": "2025-06-15T22:58:37.845087Z"
    }
   },
   "source": [
    "# --- Configuration ---\n",
    "# IMPORTANT: Update this path to where your extracted FER-2013 dataset is located.\n",
    "# For example, if you extracted fer2013.zip and the 'train' and 'test' folders\n",
    "# are inside a folder named 'fer2013' at 'D:/Projects/Deep Learning Project/'\n",
    "base_dataset_path = \"D:/Projects/Deep Learning Project\" # <--- **UPDATE THIS PATH TO YOUR FER2013 FOLDER**\n",
    "\n",
    "IMG_HEIGHT = 48  # FER-2013 images are 48x48 pixels\n",
    "IMG_WIDTH = 48\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 7  # Angry, Disgust, Fear, Happy, Sad, Surprise, Neutral\n",
    "EPOCHS = 100      # Number of training iterations. You can increase this for better performance.\n",
    "SEED = 42        # For reproducibility of random operations\n",
    "\n",
    "# Define emotion labels for consistent mapping and display\n",
    "# FER2013 labels are usually: 0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral\n",
    "# This dictionary maps the integer labels to human-readable emotion names.\n",
    "emotion_labels = {\n",
    "    0: \"Angry\",\n",
    "    1: \"Disgust\",\n",
    "    2: \"Fear\",\n",
    "    3: \"Happy\",\n",
    "    4: \"Sad\",\n",
    "    5: \"Surprise\",\n",
    "    6: \"Neutral\"\n",
    "}\n",
    "\n",
    "# --- 1. Load Data with tf.keras.utils.image_dataset_from_directory ---\n",
    "# This function is great because it infers labels from folder names.\n",
    "\n",
    "try:\n",
    "    print(f\"Loading training data from: {os.path.join(base_dataset_path, 'train')}\")\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        os.path.join(base_dataset_path, 'train'),\n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        interpolation='nearest',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        seed=SEED,\n",
    "        color_mode='grayscale' # <--- CRITICAL CHANGE: Load images as grayscale\n",
    "    )\n",
    "\n",
    "    print(f\"Loading test data from: {os.path.join(base_dataset_path, 'test')}\")\n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        os.path.join(base_dataset_path, 'test'),\n",
    "        labels='inferred',\n",
    "        label_mode='int',\n",
    "        image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        interpolation='nearest',\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        seed=SEED,\n",
    "        color_mode='grayscale' # <--- CRITICAL CHANGE: Load images as grayscale\n",
    "    )\n",
    "\n",
    "    # Get the actual class names detected by the loader (these will be the folder names)\n",
    "    class_names_detected = train_ds.class_names\n",
    "    print(f\"\\nDetected class names (from folder names): {class_names_detected}\")\n",
    "\n",
    "    # Preprocessing function: Rescale pixel values from [0,255] to [0,1]\n",
    "    def preprocess(image, label):\n",
    "        image = tf.cast(image, tf.float32) / 255.0\n",
    "        return image, label\n",
    "\n",
    "    # Apply preprocessing and optimize dataset loading for performance\n",
    "    train_ds = train_ds.map(preprocess).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    test_ds = test_ds.map(preprocess).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    print(f\"\\nNumber of training batches: {len(train_ds)}\")\n",
    "    print(f\"Number of test batches: {len(test_ds)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError loading dataset: {e}\")\n",
    "    print(f\"Please ensure the dataset is extracted correctly and '{os.path.join(base_dataset_path, 'train')}' and '{os.path.join(base_dataset_path, 'test')}' exist and contain emotion subfolders.\")\n",
    "    print(\"Exiting as data loading failed.\")\n",
    "    exit() # Exit if data loading fails\n",
    "\n",
    "# --- 2. Build the Deep Learning Model (Simple CNN Architecture) ---\n",
    "model = keras.Sequential([\n",
    "    # Input layer: expects images of IMG_HEIGHT x IMG_WIDTH with 1 color channel (grayscale)\n",
    "    # CRITICAL CHANGE: input_shape last dimension is 1\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 1)),\n",
    "    layers.BatchNormalization(), # Helps stabilize training and speed up convergence\n",
    "    layers.MaxPooling2D((2, 2)), # Reduces spatial dimensions\n",
    "    layers.Dropout(0.25),        # Randomly sets a fraction of input units to 0 at each update during training time, which helps prevent overfitting.\n",
    "\n",
    "    # Convolutional Block 2\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    # Convolutional Block 3\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    # Flatten the 3D output of convolutional layers to 1D for Dense layers\n",
    "    layers.Flatten(),\n",
    "\n",
    "    # Dense (Fully Connected) Layers\n",
    "    layers.Dense(256, activation='relu'), # You had 256 here previously, keeping it.\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5), # Higher dropout for the dense layers\n",
    "\n",
    "    # Output Layer: NUM_CLASSES neurons, 'softmax' activation for multi-class probabilities\n",
    "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "# Display model architecture summary\n",
    "print(\"\\n--- Model Architecture Summary ---\")\n",
    "model.summary()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from: D:/Projects/Deep Learning Project\\train\n",
      "Found 28709 files belonging to 7 classes.\n",
      "Loading test data from: D:/Projects/Deep Learning Project\\test\n",
      "Found 7178 files belonging to 7 classes.\n",
      "\n",
      "Detected class names (from folder names): ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
      "\n",
      "Number of training batches: 898\n",
      "Number of test batches: 225\n",
      "\n",
      "--- Model Architecture Summary ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\miyee\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001B[38;5;33mConv2D\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m46\u001B[0m, \u001B[38;5;34m46\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │           \u001B[38;5;34m320\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m46\u001B[0m, \u001B[38;5;34m46\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │           \u001B[38;5;34m128\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001B[38;5;33mMaxPooling2D\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m23\u001B[0m, \u001B[38;5;34m23\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m23\u001B[0m, \u001B[38;5;34m23\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m21\u001B[0m, \u001B[38;5;34m21\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │         \u001B[38;5;34m9,248\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m21\u001B[0m, \u001B[38;5;34m21\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │           \u001B[38;5;34m128\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m10\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │        \u001B[38;5;34m36,992\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │           \u001B[38;5;34m512\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001B[38;5;33mFlatten\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2048\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │       \u001B[38;5;34m524,544\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │         \u001B[38;5;34m1,024\u001B[0m │\n",
       "│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m)              │         \u001B[38;5;34m1,799\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,799</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m574,695\u001B[0m (2.19 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">574,695</span> (2.19 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m573,799\u001B[0m (2.19 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">573,799</span> (2.19 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m896\u001B[0m (3.50 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T03:26:11.597685Z",
     "start_time": "2025-06-14T03:26:11.580657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 3. Compile the Model ---\n",
    "# Configure the model for training\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001), # Adam is a popular and effective optimizer\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),    # Suitable for integer labels (0, 1, 2, ...)\n",
    "    metrics=['accuracy']                                  # Metric to monitor during training\n",
    ")"
   ],
   "id": "47ee0f906b6d0422",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T03:57:53.765029Z",
     "start_time": "2025-06-14T03:26:11.618036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# --- 4. Train the Model ---\n",
    "print(\"\\n--- Model Training ---\")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=test_ds, # Using the test set as validation data for simplicity in this example\n",
    "    verbose=1                # Display training progress\n",
    ")\n",
    "\n",
    "print(\"\\n--- Training Complete ---\")\n"
   ],
   "id": "64e5027d4738e4c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Training ---\n",
      "Epoch 1/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 21ms/step - accuracy: 0.2755 - loss: 2.2158 - val_accuracy: 0.4291 - val_loss: 1.4903\n",
      "Epoch 2/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 18ms/step - accuracy: 0.4250 - loss: 1.5018 - val_accuracy: 0.4809 - val_loss: 1.3767\n",
      "Epoch 3/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 19ms/step - accuracy: 0.4623 - loss: 1.4046 - val_accuracy: 0.4600 - val_loss: 1.3831\n",
      "Epoch 4/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 19ms/step - accuracy: 0.4886 - loss: 1.3449 - val_accuracy: 0.4911 - val_loss: 1.3094\n",
      "Epoch 5/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 18ms/step - accuracy: 0.5108 - loss: 1.2968 - val_accuracy: 0.5093 - val_loss: 1.3028\n",
      "Epoch 6/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 18ms/step - accuracy: 0.5180 - loss: 1.2705 - val_accuracy: 0.5295 - val_loss: 1.2475\n",
      "Epoch 7/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 18ms/step - accuracy: 0.5296 - loss: 1.2431 - val_accuracy: 0.5334 - val_loss: 1.2428\n",
      "Epoch 8/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 18ms/step - accuracy: 0.5382 - loss: 1.2135 - val_accuracy: 0.5557 - val_loss: 1.1661\n",
      "Epoch 9/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 19ms/step - accuracy: 0.5426 - loss: 1.1973 - val_accuracy: 0.4760 - val_loss: 1.3827\n",
      "Epoch 10/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 19ms/step - accuracy: 0.5536 - loss: 1.1804 - val_accuracy: 0.5690 - val_loss: 1.1427\n",
      "Epoch 11/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 20ms/step - accuracy: 0.5595 - loss: 1.1527 - val_accuracy: 0.5738 - val_loss: 1.1279\n",
      "Epoch 12/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 21ms/step - accuracy: 0.5784 - loss: 1.1220 - val_accuracy: 0.5807 - val_loss: 1.1100\n",
      "Epoch 13/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 28ms/step - accuracy: 0.5855 - loss: 1.1087 - val_accuracy: 0.5804 - val_loss: 1.1276\n",
      "Epoch 14/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 27ms/step - accuracy: 0.5897 - loss: 1.0884 - val_accuracy: 0.5500 - val_loss: 1.1955\n",
      "Epoch 15/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 28ms/step - accuracy: 0.5979 - loss: 1.0805 - val_accuracy: 0.5401 - val_loss: 1.2365\n",
      "Epoch 16/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 28ms/step - accuracy: 0.6012 - loss: 1.0590 - val_accuracy: 0.5970 - val_loss: 1.0875\n",
      "Epoch 17/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 26ms/step - accuracy: 0.6126 - loss: 1.0335 - val_accuracy: 0.5720 - val_loss: 1.1392\n",
      "Epoch 18/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 21ms/step - accuracy: 0.6134 - loss: 1.0299 - val_accuracy: 0.5713 - val_loss: 1.1529\n",
      "Epoch 19/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 23ms/step - accuracy: 0.6235 - loss: 1.0129 - val_accuracy: 0.5653 - val_loss: 1.1724\n",
      "Epoch 20/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 23ms/step - accuracy: 0.6215 - loss: 1.0015 - val_accuracy: 0.5812 - val_loss: 1.1510\n",
      "Epoch 21/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 24ms/step - accuracy: 0.6268 - loss: 0.9865 - val_accuracy: 0.5952 - val_loss: 1.0904\n",
      "Epoch 22/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 21ms/step - accuracy: 0.6376 - loss: 0.9695 - val_accuracy: 0.5853 - val_loss: 1.1329\n",
      "Epoch 23/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 20ms/step - accuracy: 0.6328 - loss: 0.9766 - val_accuracy: 0.5960 - val_loss: 1.1255\n",
      "Epoch 24/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 19ms/step - accuracy: 0.6404 - loss: 0.9547 - val_accuracy: 0.5775 - val_loss: 1.1305\n",
      "Epoch 25/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 20ms/step - accuracy: 0.6412 - loss: 0.9482 - val_accuracy: 0.6063 - val_loss: 1.0768\n",
      "Epoch 26/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m21s\u001B[0m 24ms/step - accuracy: 0.6516 - loss: 0.9292 - val_accuracy: 0.6024 - val_loss: 1.1149\n",
      "Epoch 27/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 21ms/step - accuracy: 0.6499 - loss: 0.9328 - val_accuracy: 0.5939 - val_loss: 1.1213\n",
      "Epoch 28/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 20ms/step - accuracy: 0.6555 - loss: 0.9199 - val_accuracy: 0.6020 - val_loss: 1.0963\n",
      "Epoch 29/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 19ms/step - accuracy: 0.6586 - loss: 0.9136 - val_accuracy: 0.5880 - val_loss: 1.1533\n",
      "Epoch 30/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 21ms/step - accuracy: 0.6662 - loss: 0.8956 - val_accuracy: 0.5833 - val_loss: 1.1638\n",
      "Epoch 31/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 20ms/step - accuracy: 0.6677 - loss: 0.8820 - val_accuracy: 0.5993 - val_loss: 1.1031\n",
      "Epoch 32/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 20ms/step - accuracy: 0.6721 - loss: 0.8717 - val_accuracy: 0.5940 - val_loss: 1.1575\n",
      "Epoch 33/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 23ms/step - accuracy: 0.6738 - loss: 0.8692 - val_accuracy: 0.6043 - val_loss: 1.0958\n",
      "Epoch 34/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 20ms/step - accuracy: 0.6785 - loss: 0.8614 - val_accuracy: 0.6158 - val_loss: 1.0723\n",
      "Epoch 35/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 28ms/step - accuracy: 0.6770 - loss: 0.8555 - val_accuracy: 0.6130 - val_loss: 1.0749\n",
      "Epoch 36/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m31s\u001B[0m 34ms/step - accuracy: 0.6826 - loss: 0.8540 - val_accuracy: 0.6162 - val_loss: 1.0702\n",
      "Epoch 37/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m30s\u001B[0m 34ms/step - accuracy: 0.6893 - loss: 0.8323 - val_accuracy: 0.5984 - val_loss: 1.1117\n",
      "Epoch 38/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 25ms/step - accuracy: 0.6773 - loss: 0.8757 - val_accuracy: 0.6105 - val_loss: 1.1025\n",
      "Epoch 39/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m24s\u001B[0m 27ms/step - accuracy: 0.6925 - loss: 0.8235 - val_accuracy: 0.6116 - val_loss: 1.1068\n",
      "Epoch 40/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.6924 - loss: 0.8214 - val_accuracy: 0.6081 - val_loss: 1.1080\n",
      "Epoch 41/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 21ms/step - accuracy: 0.6936 - loss: 0.8166 - val_accuracy: 0.6046 - val_loss: 1.1309\n",
      "Epoch 42/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m17s\u001B[0m 19ms/step - accuracy: 0.6945 - loss: 0.8127 - val_accuracy: 0.6148 - val_loss: 1.0944\n",
      "Epoch 43/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 20ms/step - accuracy: 0.7005 - loss: 0.7988 - val_accuracy: 0.6109 - val_loss: 1.1243\n",
      "Epoch 44/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 20ms/step - accuracy: 0.6887 - loss: 0.8357 - val_accuracy: 0.6190 - val_loss: 1.0810\n",
      "Epoch 45/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 20ms/step - accuracy: 0.7045 - loss: 0.8017 - val_accuracy: 0.5704 - val_loss: 1.2748\n",
      "Epoch 46/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 21ms/step - accuracy: 0.6988 - loss: 0.8082 - val_accuracy: 0.6045 - val_loss: 1.1167\n",
      "Epoch 47/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7085 - loss: 0.7762 - val_accuracy: 0.6071 - val_loss: 1.1371\n",
      "Epoch 48/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m27s\u001B[0m 31ms/step - accuracy: 0.7071 - loss: 0.7712 - val_accuracy: 0.5840 - val_loss: 1.1750\n",
      "Epoch 49/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 28ms/step - accuracy: 0.7139 - loss: 0.7727 - val_accuracy: 0.6133 - val_loss: 1.1218\n",
      "Epoch 50/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7119 - loss: 0.7700 - val_accuracy: 0.6167 - val_loss: 1.1055\n",
      "Epoch 51/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 21ms/step - accuracy: 0.7088 - loss: 0.7790 - val_accuracy: 0.6087 - val_loss: 1.1232\n",
      "Epoch 52/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 20ms/step - accuracy: 0.7189 - loss: 0.7593 - val_accuracy: 0.6060 - val_loss: 1.1299\n",
      "Epoch 53/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 23ms/step - accuracy: 0.7081 - loss: 0.7742 - val_accuracy: 0.6195 - val_loss: 1.0857\n",
      "Epoch 54/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m23s\u001B[0m 26ms/step - accuracy: 0.7208 - loss: 0.7527 - val_accuracy: 0.6244 - val_loss: 1.0906\n",
      "Epoch 55/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7229 - loss: 0.7433 - val_accuracy: 0.6095 - val_loss: 1.1163\n",
      "Epoch 56/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 20ms/step - accuracy: 0.7201 - loss: 0.7540 - val_accuracy: 0.6158 - val_loss: 1.1134\n",
      "Epoch 57/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 21ms/step - accuracy: 0.7241 - loss: 0.7317 - val_accuracy: 0.6170 - val_loss: 1.0897\n",
      "Epoch 58/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7265 - loss: 0.7363 - val_accuracy: 0.6133 - val_loss: 1.1167\n",
      "Epoch 59/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7261 - loss: 0.7337 - val_accuracy: 0.6119 - val_loss: 1.1405\n",
      "Epoch 60/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7259 - loss: 0.7393 - val_accuracy: 0.5446 - val_loss: 1.3364\n",
      "Epoch 61/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7191 - loss: 0.7586 - val_accuracy: 0.6206 - val_loss: 1.0930\n",
      "Epoch 62/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7341 - loss: 0.7224 - val_accuracy: 0.6230 - val_loss: 1.0982\n",
      "Epoch 63/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7341 - loss: 0.7118 - val_accuracy: 0.6183 - val_loss: 1.1223\n",
      "Epoch 64/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7334 - loss: 0.7134 - val_accuracy: 0.6080 - val_loss: 1.1346\n",
      "Epoch 65/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7271 - loss: 0.7315 - val_accuracy: 0.6206 - val_loss: 1.0995\n",
      "Epoch 66/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7299 - loss: 0.7245 - val_accuracy: 0.5932 - val_loss: 1.1538\n",
      "Epoch 67/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7399 - loss: 0.6960 - val_accuracy: 0.6183 - val_loss: 1.1076\n",
      "Epoch 68/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7380 - loss: 0.6986 - val_accuracy: 0.6091 - val_loss: 1.1512\n",
      "Epoch 69/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7435 - loss: 0.6902 - val_accuracy: 0.6205 - val_loss: 1.1180\n",
      "Epoch 70/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7386 - loss: 0.6968 - val_accuracy: 0.6174 - val_loss: 1.1226\n",
      "Epoch 71/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7429 - loss: 0.6917 - val_accuracy: 0.6174 - val_loss: 1.1354\n",
      "Epoch 72/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7419 - loss: 0.6854 - val_accuracy: 0.6112 - val_loss: 1.1583\n",
      "Epoch 73/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7453 - loss: 0.6854 - val_accuracy: 0.6179 - val_loss: 1.1230\n",
      "Epoch 74/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7493 - loss: 0.6799 - val_accuracy: 0.6151 - val_loss: 1.1545\n",
      "Epoch 75/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7419 - loss: 0.6912 - val_accuracy: 0.6176 - val_loss: 1.1294\n",
      "Epoch 76/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m19s\u001B[0m 22ms/step - accuracy: 0.7475 - loss: 0.6861 - val_accuracy: 0.6145 - val_loss: 1.1296\n",
      "Epoch 77/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 22ms/step - accuracy: 0.7527 - loss: 0.6625 - val_accuracy: 0.6159 - val_loss: 1.1366\n",
      "Epoch 78/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 23ms/step - accuracy: 0.7429 - loss: 0.6878 - val_accuracy: 0.5919 - val_loss: 1.2273\n",
      "Epoch 79/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 18ms/step - accuracy: 0.7477 - loss: 0.6753 - val_accuracy: 0.5910 - val_loss: 1.2338\n",
      "Epoch 80/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 17ms/step - accuracy: 0.7498 - loss: 0.6645 - val_accuracy: 0.5893 - val_loss: 1.2067\n",
      "Epoch 81/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 17ms/step - accuracy: 0.7517 - loss: 0.6713 - val_accuracy: 0.5798 - val_loss: 1.2930\n",
      "Epoch 82/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 17ms/step - accuracy: 0.7553 - loss: 0.6644 - val_accuracy: 0.5748 - val_loss: 1.2958\n",
      "Epoch 83/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 17ms/step - accuracy: 0.7526 - loss: 0.6647 - val_accuracy: 0.6186 - val_loss: 1.1413\n",
      "Epoch 84/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 17ms/step - accuracy: 0.7459 - loss: 0.6703 - val_accuracy: 0.5872 - val_loss: 1.2734\n",
      "Epoch 85/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 17ms/step - accuracy: 0.7593 - loss: 0.6528 - val_accuracy: 0.5971 - val_loss: 1.2166\n",
      "Epoch 86/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 17ms/step - accuracy: 0.7591 - loss: 0.6417 - val_accuracy: 0.5977 - val_loss: 1.2077\n",
      "Epoch 87/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 17ms/step - accuracy: 0.7545 - loss: 0.6542 - val_accuracy: 0.6084 - val_loss: 1.1694\n",
      "Epoch 88/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 18ms/step - accuracy: 0.7605 - loss: 0.6437 - val_accuracy: 0.6190 - val_loss: 1.1252\n",
      "Epoch 89/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 17ms/step - accuracy: 0.7622 - loss: 0.6417 - val_accuracy: 0.6241 - val_loss: 1.1164\n",
      "Epoch 90/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 18ms/step - accuracy: 0.7600 - loss: 0.6453 - val_accuracy: 0.6038 - val_loss: 1.1609\n",
      "Epoch 91/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 17ms/step - accuracy: 0.7574 - loss: 0.6511 - val_accuracy: 0.6184 - val_loss: 1.1241\n",
      "Epoch 92/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 17ms/step - accuracy: 0.7706 - loss: 0.6243 - val_accuracy: 0.6250 - val_loss: 1.1243\n",
      "Epoch 93/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 17ms/step - accuracy: 0.7558 - loss: 0.6470 - val_accuracy: 0.6220 - val_loss: 1.1418\n",
      "Epoch 94/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 17ms/step - accuracy: 0.7638 - loss: 0.6372 - val_accuracy: 0.5954 - val_loss: 1.2177\n",
      "Epoch 95/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 17ms/step - accuracy: 0.7661 - loss: 0.6317 - val_accuracy: 0.5933 - val_loss: 1.2337\n",
      "Epoch 96/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 17ms/step - accuracy: 0.7645 - loss: 0.6307 - val_accuracy: 0.6236 - val_loss: 1.1308\n",
      "Epoch 97/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 18ms/step - accuracy: 0.7638 - loss: 0.6286 - val_accuracy: 0.6213 - val_loss: 1.1463\n",
      "Epoch 98/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 17ms/step - accuracy: 0.7739 - loss: 0.6129 - val_accuracy: 0.6261 - val_loss: 1.1259\n",
      "Epoch 99/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 17ms/step - accuracy: 0.7640 - loss: 0.6377 - val_accuracy: 0.6234 - val_loss: 1.1283\n",
      "Epoch 100/100\n",
      "\u001B[1m898/898\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 17ms/step - accuracy: 0.7591 - loss: 0.6424 - val_accuracy: 0.5539 - val_loss: 1.4254\n",
      "\n",
      "--- Training Complete ---\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T04:38:50.945096Z",
     "start_time": "2025-06-14T04:38:49.998600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 5. Evaluate the Model on the Test Set ---\n",
    "print(\"\\n--- Model Evaluation ---\")\n",
    "test_loss, test_accuracy = model.evaluate(test_ds, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ],
   "id": "f090b33e677d0f6e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Evaluation ---\n",
      "Test Loss: 1.4254\n",
      "Test Accuracy: 0.5539\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T04:38:51.412528Z",
     "start_time": "2025-06-14T04:38:51.263947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "import datetime\n",
    "# Save training history to versioned CSV in 'history' folder\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df['time'] = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "os.makedirs('history', exist_ok=True)\n",
    "history_filename = os.path.join('history', f\"training_history_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\")\n",
    "history_df.to_csv(history_filename, index=False)\n",
    "print(f\"📁 Training history saved to {history_filename}\")"
   ],
   "id": "24ea60ab94c30517",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Training history saved to history\\training_history_20250614_003851.csv\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T04:38:51.462759Z",
     "start_time": "2025-06-14T04:38:51.454801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_train_accuracy = history.history['accuracy'][-1]\n",
    "final_val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "print(f\"\\nFinal Training Accuracy (last epoch): {final_train_accuracy:.4f}\")\n",
    "print(f\"Final Validation Accuracy (last epoch): {final_val_accuracy:.4f}\")"
   ],
   "id": "9108161fd2ab1770",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Training Accuracy (last epoch): 0.7646\n",
      "Final Validation Accuracy (last epoch): 0.5539\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T04:43:42.030999Z",
     "start_time": "2025-06-14T04:43:41.989999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save Model and Label Map\n",
    "import json\n",
    "\n",
    "model.save('emotion_recognition_model.h5')\n",
    "with open('emotion_labels.json', 'w') as f:\n",
    "    json.dump(emotion_labels, f)"
   ],
   "id": "d1cdc634ba9a60fe",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T22:59:25.044265Z",
     "start_time": "2025-06-15T22:59:24.722673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import pandas as pd\n",
    "all_train_labels = []\n",
    "for images, labels in train_ds:\n",
    "    all_train_labels.extend(labels.numpy())\n",
    "\n",
    "# Convert the list of labels to a Pandas Series for easy counting\n",
    "train_labels_series = pd.Series(all_train_labels)\n",
    "\n",
    "# --- Step 2: Get the counts for each emotion class ---\n",
    "# .value_counts() gives the frequency of each unique label\n",
    "# .sort_index() ensures the emotions are ordered by their numerical label (0, 1, 2, ...)\n",
    "class_counts = train_labels_series.value_counts().sort_index()\n",
    "print(class_counts)"
   ],
   "id": "1bbcc754d612ffff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3995\n",
      "1     436\n",
      "2    4097\n",
      "3    7215\n",
      "4    4965\n",
      "5    4830\n",
      "6    3171\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T23:00:49.631250Z",
     "start_time": "2025-06-15T23:00:49.625131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ordered_emotion_names = [emotion_labels[i] for i in sorted(emotion_labels.keys())]\n",
    "print(ordered_emotion_names)"
   ],
   "id": "bb2ff8425a45e78f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
